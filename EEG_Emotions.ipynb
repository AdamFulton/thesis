{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamFulton/thesis/blob/main/EEG_Emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 709,
      "metadata": {
        "id": "cJN9im36VIdb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader,SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pickle as pickle\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 710,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNkgPatpVQAZ",
        "outputId": "fecf3f86-10eb-41c1-d3cd-94ba9b105d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 20 12:14:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    39W / 250W |  11599MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 711,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J5bfscsVQvi",
        "outputId": "156c78ee-cc79-4d68-e801-add61e73cbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 712,
      "metadata": {
        "id": "YfbW8rTXVhs5"
      },
      "outputs": [],
      "source": [
        "def read_eeg_signal_from_file(filename):\n",
        "    x = pickle._Unpickler(open(filename, 'rb'))\n",
        "    x.encoding = 'latin1'\n",
        "    p = x.load()\n",
        "    return p\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 713,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luuB-fKL-YJK",
        "outputId": "b38e5f01-07d5-4a79-ca5e-4a71e15a06ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\n"
          ]
        }
      ],
      "source": [
        "files = []\n",
        "for n in range(1, 33): \n",
        "    s = ''\n",
        "    if n < 10:\n",
        "        s += '0'\n",
        "    s += str(n)\n",
        "    files.append(s)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 714,
      "metadata": {
        "id": "J9bAG7DT-ZtL"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels = []\n",
        "data = []\n",
        "\n",
        "for i in files: \n",
        "    filename = \"/content/gdrive/MyDrive/data_preprocessed_python/s\" + i + \".dat\"\n",
        "    trial = read_eeg_signal_from_file(filename)\n",
        "    labels.append(trial['labels'])\n",
        "    data.append(trial['data'])\n",
        "\n",
        "labels = np.array(labels)\n",
        "labels = labels.flatten()\n",
        "labels = labels.reshape(1280, 4)\n",
        "\n",
        "data = np.array(data)\n",
        "data = data.flatten()\n",
        "data = data.reshape(1280, 40, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 715,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0LuHpU-bzn",
        "outputId": "fbb75889-5076-4705-bc22-9f1a353e9c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1280, 4)\n",
            "Data:  (1280, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "print(\"Labels: \", labels.shape)\n",
        "print(\"Data: \", data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 716,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfASJG9k-dUz",
        "outputId": "d474d2e0-58ea-40d2-9862-a62230dc97e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Valence      Arousal\n",
            "count  1280.000000  1280.000000\n",
            "mean      5.254313     5.156711\n",
            "std       2.130816     2.020499\n",
            "min       1.000000     1.000000\n",
            "25%       3.867500     3.762500\n",
            "50%       5.040000     5.230000\n",
            "75%       7.050000     6.950000\n",
            "max       9.000000     9.000000\n"
          ]
        }
      ],
      "source": [
        "df_label_ratings = pd.DataFrame({'Valence': labels[:,0], 'Arousal': labels[:,1]})\n",
        "print(df_label_ratings.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 717,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acmGHCxF-dF8",
        "outputId": "e3f82599-93b8-4b7b-849c-212a74104a11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Valence  Arousal\n",
            "0      7.71     7.60\n",
            "1      8.10     7.31\n",
            "2      8.58     7.54\n",
            "3      4.94     6.01\n",
            "4      6.96     3.92\n",
            "5      8.27     3.92\n",
            "6      7.44     3.73\n",
            "7      7.32     2.55\n",
            "8      4.04     3.29\n",
            "9      1.99     4.86\n",
            "10     2.99     2.36\n",
            "11     2.71     2.77\n",
            "12     1.95     3.12\n",
            "13     4.18     2.24\n",
            "14     3.17     8.08\n"
          ]
        }
      ],
      "source": [
        "print(df_label_ratings.head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 718,
      "metadata": {
        "id": "F6iHWrSg-ofL"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_hahv = df_label_ratings[(df_label_ratings['Valence'] >= np.median(labels[:,0])) & (df_label_ratings['Arousal'] >= np.median(labels[:,1]))]\n",
        "\n",
        "df_lahv = df_label_ratings[(df_label_ratings['Valence'] >= np.median(labels[:,0])) & (df_label_ratings['Arousal'] < np.median(labels[:,1]))]\n",
        "\n",
        "df_halv = df_label_ratings[(df_label_ratings['Valence'] < np.median(labels[:,0])) & (df_label_ratings['Arousal'] >= np.median(labels[:,1]))]\n",
        "\n",
        "df_lalv = df_label_ratings[(df_label_ratings['Valence'] < np.median(labels[:,0])) & (df_label_ratings['Arousal'] < np.median(labels[:,1]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 719,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHINl7qh-ubS",
        "outputId": "ade214fc-4490-40cc-f0bb-b0251337009a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Valence: 680\n",
            "Negative Valence: 600\n",
            "High Arousal: 640\n",
            "Low Arousal: 640\n"
          ]
        }
      ],
      "source": [
        "print(\"Positive Valence:\", str(len(df_hahv) + len(df_lahv)))\n",
        "print(\"Negative Valence:\", str(len(df_halv) + len(df_lalv)))\n",
        "print(\"High Arousal:\", str(len(df_hahv) + len(df_halv)))\n",
        "print(\"Low Arousal:\", str(len(df_lahv) + len(df_lalv)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 720,
      "metadata": {
        "id": "AaJabfbq-v6o"
      },
      "outputs": [],
      "source": [
        "def positive_valence(trial):\n",
        "    return 1 if labels[trial,0] >= np.median(labels[:,0]) else 0 \n",
        "\n",
        "def high_arousal(trial):\n",
        "    return 1 if labels[trial,1] >= np.median(labels[:,1]) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 721,
      "metadata": {
        "id": "ySmfjKk6-xoF"
      },
      "outputs": [],
      "source": [
        "labels_encoded = []\n",
        "for i in range (len(labels)):\n",
        "  labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
        "\n",
        "labels_encoded = np.reshape(labels_encoded, (1280, 2))\n",
        "df_labels = pd.DataFrame(data=labels_encoded, columns=[\"Positive Valence\", \"High Arousal\",])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 722,
      "metadata": {
        "id": "1wcAUsAQ-3TA"
      },
      "outputs": [],
      "source": [
        "df_valence = df_labels['Positive Valence']\n",
        "\n",
        "df_arousal = df_labels['High Arousal']\n",
        "\n",
        "df_arousal = df_arousal.to_numpy()\n",
        "\n",
        "df_valence = df_valence.to_numpy()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 723,
      "metadata": {
        "id": "k42Z2F-74egK"
      },
      "outputs": [],
      "source": [
        "eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n",
        "peripheral_channels = np.array([\"hEOG\", \"vEOG\", \"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 724,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xsc1bSs4g56",
        "outputId": "d9288788-e873-4683-c72b-5fe30177d28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ],
      "source": [
        "eeg_data = []\n",
        "for i in range (len(data)):\n",
        "    for j in range (len(eeg_channels)):\n",
        "        eeg_data.append(data[i,j])\n",
        "eeg_data = np.reshape(eeg_data, (len(data), len(eeg_channels), len(data[0,0])))\n",
        "print(eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 725,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkqW9zjxAWsP",
        "outputId": "dc15597f-6d49-4346-82f5-9cc50cee9513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "(array([[  6.64561064,   1.9759769 , -10.09336038, ...,  -4.57772463,\n",
            "        -10.84032221,   1.1085339 ],\n",
            "       [ -5.81715954,  -5.61460809,   5.7950419 , ...,   6.59908672,\n",
            "         13.79812842,   0.24619464],\n",
            "       [  8.74115315,  -0.89235998,  -8.36698485, ...,  -0.14069965,\n",
            "         -9.18724516,  -5.58496531],\n",
            "       ...,\n",
            "       [ -5.74765687,  -0.57955561,  -0.11323674, ...,  -3.57586788,\n",
            "         -1.38762967,   3.55055799],\n",
            "       [-10.3232662 ,  -4.68424519,  -6.79691768, ...,  -1.63490355,\n",
            "          0.03873261,   9.83660886],\n",
            "       [-15.25537631,  -6.07457524,  -4.84078595, ...,  -0.57490218,\n",
            "          2.4679468 ,  13.10621666]]), 1)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(0.8 * len(eeg_data))\n",
        "valid_size = len(eeg_data) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(eeg_data, [train_size, valid_size])\n",
        "train_dataset = np.array(train_dataset)\n",
        "valid_dataset = np.array(valid_dataset)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train = []\n",
        "valid = []\n",
        "print(len(train_dataset))\n",
        "for i in range(valid_size,train_size):\n",
        "\n",
        "    valid.append((train_dataset[i], df_valence[i]))\n",
        "  \n",
        "\n",
        "for i in range(0,len(valid_dataset)):\n",
        "\n",
        "    train.append((valid_dataset[i],df_valence[i]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KOpHJXTaYy-"
      },
      "outputs": [],
      "source": [
        "batch_size=22\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train,batch_size)\n",
        "\n",
        "\n",
        "valid_dl = DataLoader(valid,batch_size)\n",
        "\n",
        "\n",
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 856,
      "metadata": {
        "id": "D_jZvIcOb8n7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        def conv_bn(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv1d(inp, oup, 2, stride, 1, bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(p=0.25),\n",
        "                nn.BatchNorm1d(oup),\n",
        "            )\n",
        "\n",
        "        def conv_dw(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv1d(inp, inp, 2, stride, 1, groups=inp, bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(p=0.25),\n",
        "                nn.BatchNorm1d(inp),\n",
        "                \n",
        "              \n",
        "    \n",
        "                nn.Conv1d(inp, oup, 2, 1, 0, bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(p=0.25),\n",
        "                nn.BatchNorm1d(oup),\n",
        "               \n",
        "               \n",
        "            )\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            conv_bn( 32,  64, 2), \n",
        "            conv_dw( 64,  84, 1),\n",
        "            conv_dw( 84, 104, 2),\n",
        "            conv_dw(104, 124, 1),\n",
        "            conv_dw(124, 144, 2),\n",
        "            conv_dw(144, 164, 1),\n",
        "            conv_dw(164, 184, 2),\n",
        "            conv_dw(184, 204, 1),\n",
        "            conv_dw(204, 256, 2),\n",
        "            conv_dw(256, 312, 1),\n",
        "            conv_dw(312, 412, 2),\n",
        "            conv_dw(412, 512, 2),\n",
        "            nn.AvgPool1d(60),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "        nn.Linear(512, 256),\n",
        "      \tnn.ReLU(),\n",
        "        nn.Dropout(p=0.75),\n",
        "        nn.Linear(256, 124),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.75),\n",
        "        nn.Linear(124, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.75),\n",
        "        nn.Linear(64, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.75),\n",
        "        nn.Linear(32, 12),\n",
        "        nn.Softmax(),\n",
        "        nn.Linear(12,2)\n",
        "        \n",
        "\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = x.view(-1, 512)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 832,
      "metadata": {
        "id": "yhWdCylqcCaL"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device(\"cuda\")\n",
        "\n",
        "  else:\n",
        "    return torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 833,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbNQ80gIWapv",
        "outputId": "3b631c5f-5e79-4c8d-d297-72a5bea98185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 833
        }
      ],
      "source": [
        "device = get_default_device();\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 834,
      "metadata": {
        "id": "B_iltgDnWbgM"
      },
      "outputs": [],
      "source": [
        "def to_device(data,device):\n",
        "\n",
        "  if isinstance(data,(list,tuple)):\n",
        "    return [to_device(x,device) for x in data]\n",
        "\n",
        "  return data.to(device,non_blocking=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 835,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jNuP1TxWdug",
        "outputId": "34874f23-79c5-411a-a86e-8004c4a8fdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([22, 32, 8064])\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "for data,labels in train_dl:\n",
        "  print(data.shape)\n",
        "  data = to_device(data,device)\n",
        "  print(data.device)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 836,
      "metadata": {
        "id": "iNr5k3NgWtaK"
      },
      "outputs": [],
      "source": [
        "class DeviceDataLoader():\n",
        "    \n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "       \n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 857,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZSMNplsWuFW",
        "outputId": "425d3c32-dc86-43ae-c5cc-61e8d83a3408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv1d(32, 64, kernel_size=(2,), stride=(2,), padding=(1,), bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,), groups=64, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(64, 84, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv1d(84, 84, kernel_size=(2,), stride=(2,), padding=(1,), groups=84, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(84, 104, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv1d(104, 104, kernel_size=(2,), stride=(1,), padding=(1,), groups=104, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(104, 124, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv1d(124, 124, kernel_size=(2,), stride=(2,), padding=(1,), groups=124, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(124, 144, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Conv1d(144, 144, kernel_size=(2,), stride=(1,), padding=(1,), groups=144, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(144, 164, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Conv1d(164, 164, kernel_size=(2,), stride=(2,), padding=(1,), groups=164, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(164, 184, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Conv1d(184, 184, kernel_size=(2,), stride=(1,), padding=(1,), groups=184, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(184, 204, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (0): Conv1d(204, 204, kernel_size=(2,), stride=(2,), padding=(1,), groups=204, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(204, 256, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (0): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,), groups=256, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(256, 312, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (0): Conv1d(312, 312, kernel_size=(2,), stride=(2,), padding=(1,), groups=312, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(312, 412, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(412, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (0): Conv1d(412, 412, kernel_size=(2,), stride=(2,), padding=(1,), groups=412, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.25, inplace=False)\n",
              "      (3): BatchNorm1d(412, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv1d(412, 512, kernel_size=(2,), stride=(1,), bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Dropout(p=0.25, inplace=False)\n",
              "      (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (12): AvgPool1d(kernel_size=(60,), stride=(60,), padding=(0,))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.75, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=124, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.75, inplace=False)\n",
              "    (6): Linear(in_features=124, out_features=64, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.75, inplace=False)\n",
              "    (9): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.75, inplace=False)\n",
              "    (12): Linear(in_features=32, out_features=12, bias=True)\n",
              "    (13): Softmax(dim=None)\n",
              "    (14): Linear(in_features=12, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 857
        }
      ],
      "source": [
        "train_dl  = DeviceDataLoader(train_dl,device)\n",
        "valid_dl = DeviceDataLoader(valid_dl,device)\n",
        "model = Net()\n",
        "to_device(model,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 824,
      "metadata": {
        "id": "ze5MfUci47hf"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs,labels):\n",
        "    _, preds = torch.max(outputs,dim=1)\n",
        "    return torch.sum(preds == labels).item() / len(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 862,
      "metadata": {
        "id": "wrgbVYbeW4TN"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "min_valid_loss = np.inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 863,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SibKmDpNW8Jg",
        "outputId": "dafd7228-ed5d-4f7e-f28a-81099255ce30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \t\t Train Accuracy: 0.43359375 \t\t Training Loss: 0.7152092158794403 \t\t Valid Accuracy: 0.4908854365348816 \t\t Validation Loss: 0.4606847405433655\n",
            "Validation Loss Decreased(inf--->16.123966) \t Saving The Model\n",
            "Epoch 2 \t\t Train Accuracy: 0.43359375 \t\t Training Loss: 0.7110955317815145 \t\t Valid Accuracy: 0.4908854365348816 \t\t Validation Loss: 0.4528971791267395\n",
            "Validation Loss Decreased(16.123966--->15.851401) \t Saving The Model\n",
            "Epoch 3 \t\t Train Accuracy: 0.43359375 \t\t Training Loss: 0.7069870481888453 \t\t Valid Accuracy: 0.4908854365348816 \t\t Validation Loss: 0.4450886964797974\n",
            "Validation Loss Decreased(15.851401--->15.578104) \t Saving The Model\n",
            "Epoch 4 \t\t Train Accuracy: 0.43359375 \t\t Training Loss: 0.703812782963117 \t\t Valid Accuracy: 0.4908854365348816 \t\t Validation Loss: 0.436947762966156\n",
            "Validation Loss Decreased(15.578104--->15.293172) \t Saving The Model\n",
            "Epoch 5 \t\t Train Accuracy: 0.43359375 \t\t Training Loss: 0.7006748815377554 \t\t Valid Accuracy: 0.4908854365348816 \t\t Validation Loss: 0.42955230474472045\n",
            "Validation Loss Decreased(15.293172--->15.034331) \t Saving The Model\n",
            "Epoch 6 \t\t Train Accuracy: 0.4296875 \t\t Training Loss: 0.6977109511693319 \t\t Valid Accuracy: 0.4908854365348816 \t\t Validation Loss: 0.4213708519935608\n",
            "Validation Loss Decreased(15.034331--->14.747980) \t Saving The Model\n",
            "Epoch 7 \t\t Train Accuracy: 0.44921875 \t\t Training Loss: 0.6953105628490448 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.41091506481170653\n",
            "Validation Loss Decreased(14.747980--->14.382027) \t Saving The Model\n",
            "Epoch 8 \t\t Train Accuracy: 0.53125 \t\t Training Loss: 0.6930406987667084 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3962127685546875\n",
            "Validation Loss Decreased(14.382027--->13.867447) \t Saving The Model\n",
            "Epoch 9 \t\t Train Accuracy: 0.57421875 \t\t Training Loss: 0.6876723766326904 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3872522234916687\n",
            "Validation Loss Decreased(13.867447--->13.553828) \t Saving The Model\n",
            "Epoch 10 \t\t Train Accuracy: 0.5546875 \t\t Training Loss: 0.6882494539022446 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.38140504360198973\n",
            "Validation Loss Decreased(13.553828--->13.349177) \t Saving The Model\n",
            "Epoch 11 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6821649869283041 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.377259635925293\n",
            "Validation Loss Decreased(13.349177--->13.204087) \t Saving The Model\n",
            "Epoch 12 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6852224518855413 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.37215367555618284\n",
            "Validation Loss Decreased(13.204087--->13.025379) \t Saving The Model\n",
            "Epoch 13 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6826432943344116 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3687228798866272\n",
            "Validation Loss Decreased(13.025379--->12.905301) \t Saving The Model\n",
            "Epoch 14 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6826391021410624 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.36655240058898925\n",
            "Validation Loss Decreased(12.905301--->12.829334) \t Saving The Model\n",
            "Epoch 15 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6828586409489313 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3657205939292908\n",
            "Validation Loss Decreased(12.829334--->12.800221) \t Saving The Model\n",
            "Epoch 16 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6788460463285446 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.36443030834198\n",
            "Validation Loss Decreased(12.800221--->12.755061) \t Saving The Model\n",
            "Epoch 17 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6785138646761576 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3622750997543335\n",
            "Validation Loss Decreased(12.755061--->12.679628) \t Saving The Model\n",
            "Epoch 18 \t\t Train Accuracy: 0.55859375 \t\t Training Loss: 0.6836754630009333 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3615543723106384\n",
            "Validation Loss Decreased(12.679628--->12.654403) \t Saving The Model\n",
            "Epoch 19 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6812553505102793 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.36100269556045533\n",
            "Validation Loss Decreased(12.654403--->12.635094) \t Saving The Model\n",
            "Epoch 20 \t\t Train Accuracy: 0.5625 \t\t Training Loss: 0.6814827968676885 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3601711392402649\n",
            "Validation Loss Decreased(12.635094--->12.605990) \t Saving The Model\n",
            "Epoch 21 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6795717279116312 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3596940994262695\n",
            "Validation Loss Decreased(12.605990--->12.589293) \t Saving The Model\n",
            "Epoch 22 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6772824128468832 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3587257146835327\n",
            "Validation Loss Decreased(12.589293--->12.555400) \t Saving The Model\n",
            "Epoch 23 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.679884801308314 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3579567432403564\n",
            "Validation Loss Decreased(12.555400--->12.528486) \t Saving The Model\n",
            "Epoch 24 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6838404685258865 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3578149080276489\n",
            "Validation Loss Decreased(12.528486--->12.523522) \t Saving The Model\n",
            "Epoch 25 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6833506673574448 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.35766037702560427\n",
            "Validation Loss Decreased(12.523522--->12.518113) \t Saving The Model\n",
            "Epoch 26 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6758011132478714 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3568802118301392\n",
            "Validation Loss Decreased(12.518113--->12.490807) \t Saving The Model\n",
            "Epoch 27 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6799388577540716 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3555436134338379\n",
            "Validation Loss Decreased(12.490807--->12.444026) \t Saving The Model\n",
            "Epoch 28 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6819412012894949 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3546115279197693\n",
            "Validation Loss Decreased(12.444026--->12.411403) \t Saving The Model\n",
            "Epoch 29 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.680361787478129 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.35369560718536375\n",
            "Validation Loss Decreased(12.411403--->12.379346) \t Saving The Model\n",
            "Epoch 30 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6781877229611079 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.35306782722473146\n",
            "Validation Loss Decreased(12.379346--->12.357374) \t Saving The Model\n",
            "Epoch 31 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6769091089566549 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.35243074893951415\n",
            "Validation Loss Decreased(12.357374--->12.335076) \t Saving The Model\n",
            "Epoch 32 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6763948400815328 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3513179898262024\n",
            "Validation Loss Decreased(12.335076--->12.296130) \t Saving The Model\n",
            "Epoch 33 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6753857384125391 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3508652329444885\n",
            "Validation Loss Decreased(12.296130--->12.280283) \t Saving The Model\n",
            "Epoch 34 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6743866701920828 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3497533679008484\n",
            "Validation Loss Decreased(12.280283--->12.241368) \t Saving The Model\n",
            "Epoch 35 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6714327484369278 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34848432540893554\n",
            "Validation Loss Decreased(12.241368--->12.196951) \t Saving The Model\n",
            "Epoch 36 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6780556937058767 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3482603788375854\n",
            "Validation Loss Decreased(12.196951--->12.189113) \t Saving The Model\n",
            "Epoch 37 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.679048553109169 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34858453273773193\n",
            "Epoch 38 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.674508218963941 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3478386640548706\n",
            "Validation Loss Decreased(12.189113--->12.174353) \t Saving The Model\n",
            "Epoch 39 \t\t Train Accuracy: 0.5625 \t\t Training Loss: 0.6753268539905548 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3469818949699402\n",
            "Validation Loss Decreased(12.174353--->12.144366) \t Saving The Model\n",
            "Epoch 40 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6717985222736994 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3463119864463806\n",
            "Validation Loss Decreased(12.144366--->12.120920) \t Saving The Model\n",
            "Epoch 41 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6729859511057535 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3453443169593811\n",
            "Validation Loss Decreased(12.120920--->12.087051) \t Saving The Model\n",
            "Epoch 42 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6701066692670187 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34464508295059204\n",
            "Validation Loss Decreased(12.087051--->12.062578) \t Saving The Model\n",
            "Epoch 43 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6765526731808981 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3439195990562439\n",
            "Validation Loss Decreased(12.062578--->12.037186) \t Saving The Model\n",
            "Epoch 44 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6737270355224609 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3431905746459961\n",
            "Validation Loss Decreased(12.037186--->12.011670) \t Saving The Model\n",
            "Epoch 45 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6700804928938547 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3425785303115845\n",
            "Validation Loss Decreased(12.011670--->11.990249) \t Saving The Model\n",
            "Epoch 46 \t\t Train Accuracy: 0.5625 \t\t Training Loss: 0.67449884613355 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34258954524993895\n",
            "Epoch 47 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6676763395468394 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3420998454093933\n",
            "Validation Loss Decreased(11.990249--->11.973495) \t Saving The Model\n",
            "Epoch 48 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6694913307825724 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34167287349700926\n",
            "Validation Loss Decreased(11.973495--->11.958551) \t Saving The Model\n",
            "Epoch 49 \t\t Train Accuracy: 0.5625 \t\t Training Loss: 0.671935960650444 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34092514514923095\n",
            "Validation Loss Decreased(11.958551--->11.932380) \t Saving The Model\n",
            "Epoch 50 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6657160967588425 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3401603579521179\n",
            "Validation Loss Decreased(11.932380--->11.905613) \t Saving The Model\n",
            "Epoch 51 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.664721483985583 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3394202828407288\n",
            "Validation Loss Decreased(11.905613--->11.879710) \t Saving The Model\n",
            "Epoch 52 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6720030903816223 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33882626295089724\n",
            "Validation Loss Decreased(11.879710--->11.858919) \t Saving The Model\n",
            "Epoch 53 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6719946811596552 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33835755586624144\n",
            "Validation Loss Decreased(11.858919--->11.842514) \t Saving The Model\n",
            "Epoch 54 \t\t Train Accuracy: 0.5703125 \t\t Training Loss: 0.6630870501200358 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33743934631347655\n",
            "Validation Loss Decreased(11.842514--->11.810377) \t Saving The Model\n",
            "Epoch 55 \t\t Train Accuracy: 0.5625 \t\t Training Loss: 0.670084352294604 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3366392612457275\n",
            "Validation Loss Decreased(11.810377--->11.782374) \t Saving The Model\n",
            "Epoch 56 \t\t Train Accuracy: 0.56640625 \t\t Training Loss: 0.6650269677241644 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3360362648963928\n",
            "Validation Loss Decreased(11.782374--->11.761269) \t Saving The Model\n",
            "Epoch 57 \t\t Train Accuracy: 0.58984375 \t\t Training Loss: 0.6690508077541987 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3355492830276489\n",
            "Validation Loss Decreased(11.761269--->11.744225) \t Saving The Model\n",
            "Epoch 58 \t\t Train Accuracy: 0.62109375 \t\t Training Loss: 0.6659577290217081 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33521146774291993\n",
            "Validation Loss Decreased(11.744225--->11.732401) \t Saving The Model\n",
            "Epoch 59 \t\t Train Accuracy: 0.62109375 \t\t Training Loss: 0.6650702555974325 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33492422103881836\n",
            "Validation Loss Decreased(11.732401--->11.722348) \t Saving The Model\n",
            "Epoch 60 \t\t Train Accuracy: 0.61328125 \t\t Training Loss: 0.6657241682211558 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.334503972530365\n",
            "Validation Loss Decreased(11.722348--->11.707639) \t Saving The Model\n",
            "Epoch 61 \t\t Train Accuracy: 0.6171875 \t\t Training Loss: 0.6603564471006393 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3337134003639221\n",
            "Validation Loss Decreased(11.707639--->11.679969) \t Saving The Model\n",
            "Epoch 62 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.6612924188375473 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33302786350250246\n",
            "Validation Loss Decreased(11.679969--->11.655975) \t Saving The Model\n",
            "Epoch 63 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6633768031994501 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3328251242637634\n",
            "Validation Loss Decreased(11.655975--->11.648879) \t Saving The Model\n",
            "Epoch 64 \t\t Train Accuracy: 0.64453125 \t\t Training Loss: 0.6625714004039764 \t\t Valid Accuracy: 0.5104166865348816 \t\t Validation Loss: 0.3326635479927063\n",
            "Validation Loss Decreased(11.648879--->11.643224) \t Saving The Model\n",
            "Epoch 65 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.6651214361190796 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3327937602996826\n",
            "Epoch 66 \t\t Train Accuracy: 0.62890625 \t\t Training Loss: 0.6629451910654703 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33244982957839964\n",
            "Validation Loss Decreased(11.643224--->11.635744) \t Saving The Model\n",
            "Epoch 67 \t\t Train Accuracy: 0.58984375 \t\t Training Loss: 0.6727621952692667 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3324150681495667\n",
            "Validation Loss Decreased(11.635744--->11.634527) \t Saving The Model\n",
            "Epoch 68 \t\t Train Accuracy: 0.62890625 \t\t Training Loss: 0.6567687938610712 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3319926381111145\n",
            "Validation Loss Decreased(11.634527--->11.619742) \t Saving The Model\n",
            "Epoch 69 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.664653072754542 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33126990795135497\n",
            "Validation Loss Decreased(11.619742--->11.594447) \t Saving The Model\n",
            "Epoch 70 \t\t Train Accuracy: 0.609375 \t\t Training Loss: 0.6639099617799123 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3304437518119812\n",
            "Validation Loss Decreased(11.594447--->11.565531) \t Saving The Model\n",
            "Epoch 71 \t\t Train Accuracy: 0.609375 \t\t Training Loss: 0.6618684207399687 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32994879484176637\n",
            "Validation Loss Decreased(11.565531--->11.548208) \t Saving The Model\n",
            "Epoch 72 \t\t Train Accuracy: 0.6328125 \t\t Training Loss: 0.6628396163384119 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3297209143638611\n",
            "Validation Loss Decreased(11.548208--->11.540232) \t Saving The Model\n",
            "Epoch 73 \t\t Train Accuracy: 0.62890625 \t\t Training Loss: 0.664546380440394 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32976815700531004\n",
            "Epoch 74 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6617361903190613 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3296694874763489\n",
            "Validation Loss Decreased(11.540232--->11.538432) \t Saving The Model\n",
            "Epoch 75 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6552348633607229 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3294762969017029\n",
            "Validation Loss Decreased(11.538432--->11.531670) \t Saving The Model\n",
            "Epoch 76 \t\t Train Accuracy: 0.6171875 \t\t Training Loss: 0.6603454872965813 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3289664626121521\n",
            "Validation Loss Decreased(11.531670--->11.513826) \t Saving The Model\n",
            "Epoch 77 \t\t Train Accuracy: 0.65234375 \t\t Training Loss: 0.6555909117062887 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32862478494644165\n",
            "Validation Loss Decreased(11.513826--->11.501867) \t Saving The Model\n",
            "Epoch 78 \t\t Train Accuracy: 0.6171875 \t\t Training Loss: 0.6621824701627096 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32817227840423585\n",
            "Validation Loss Decreased(11.501867--->11.486030) \t Saving The Model\n",
            "Epoch 79 \t\t Train Accuracy: 0.62890625 \t\t Training Loss: 0.6583751564224561 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32764445543289183\n",
            "Validation Loss Decreased(11.486030--->11.467556) \t Saving The Model\n",
            "Epoch 80 \t\t Train Accuracy: 0.61328125 \t\t Training Loss: 0.6608103811740875 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.327230429649353\n",
            "Validation Loss Decreased(11.467556--->11.453065) \t Saving The Model\n",
            "Epoch 81 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6634384989738464 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32706230878829956\n",
            "Validation Loss Decreased(11.453065--->11.447181) \t Saving The Model\n",
            "Epoch 82 \t\t Train Accuracy: 0.6171875 \t\t Training Loss: 0.6571932385365168 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3267855763435364\n",
            "Validation Loss Decreased(11.447181--->11.437495) \t Saving The Model\n",
            "Epoch 83 \t\t Train Accuracy: 0.65625 \t\t Training Loss: 0.6472244933247566 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3263455152511597\n",
            "Validation Loss Decreased(11.437495--->11.422093) \t Saving The Model\n",
            "Epoch 84 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.659565751751264 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3263289213180542\n",
            "Validation Loss Decreased(11.422093--->11.421512) \t Saving The Model\n",
            "Epoch 85 \t\t Train Accuracy: 0.64453125 \t\t Training Loss: 0.6536709169546763 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3258228063583374\n",
            "Validation Loss Decreased(11.421512--->11.403798) \t Saving The Model\n",
            "Epoch 86 \t\t Train Accuracy: 0.5859375 \t\t Training Loss: 0.6770821213722229 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3252442002296448\n",
            "Validation Loss Decreased(11.403798--->11.383547) \t Saving The Model\n",
            "Epoch 87 \t\t Train Accuracy: 0.6171875 \t\t Training Loss: 0.6609620278080305 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32513712644577025\n",
            "Validation Loss Decreased(11.383547--->11.379799) \t Saving The Model\n",
            "Epoch 88 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.6603069603443146 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3250568389892578\n",
            "Validation Loss Decreased(11.379799--->11.376989) \t Saving The Model\n",
            "Epoch 89 \t\t Train Accuracy: 0.65234375 \t\t Training Loss: 0.6547406613826752 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32519896030426027\n",
            "Epoch 90 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6495608811577162 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3252191662788391\n",
            "Epoch 91 \t\t Train Accuracy: 0.62109375 \t\t Training Loss: 0.6571728015939394 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32506885528564455\n",
            "Epoch 92 \t\t Train Accuracy: 0.58984375 \t\t Training Loss: 0.6656794100999832 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3250113844871521\n",
            "Validation Loss Decreased(11.376989--->11.375398) \t Saving The Model\n",
            "Epoch 93 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6473305051525434 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3247905492782593\n",
            "Validation Loss Decreased(11.375398--->11.367669) \t Saving The Model\n",
            "Epoch 94 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6529708604017893 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32413086891174314\n",
            "Validation Loss Decreased(11.367669--->11.344580) \t Saving The Model\n",
            "Epoch 95 \t\t Train Accuracy: 0.6328125 \t\t Training Loss: 0.6541203459103903 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32347830533981325\n",
            "Validation Loss Decreased(11.344580--->11.321741) \t Saving The Model\n",
            "Epoch 96 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.645162912706534 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3233299255371094\n",
            "Validation Loss Decreased(11.321741--->11.316547) \t Saving The Model\n",
            "Epoch 97 \t\t Train Accuracy: 0.65625 \t\t Training Loss: 0.6473019321759542 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32321122884750364\n",
            "Validation Loss Decreased(11.316547--->11.312393) \t Saving The Model\n",
            "Epoch 98 \t\t Train Accuracy: 0.65234375 \t\t Training Loss: 0.6465982149044672 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.32280668020248415\n",
            "Validation Loss Decreased(11.312393--->11.298234) \t Saving The Model\n",
            "Epoch 99 \t\t Train Accuracy: 0.66796875 \t\t Training Loss: 0.6431140179435412 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3222344398498535\n",
            "Validation Loss Decreased(11.298234--->11.278205) \t Saving The Model\n",
            "Epoch 100 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6392750864227613 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3215397834777832\n",
            "Validation Loss Decreased(11.278205--->11.253892) \t Saving The Model\n",
            "Epoch 101 \t\t Train Accuracy: 0.64453125 \t\t Training Loss: 0.6473844076196352 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3211702466011047\n",
            "Validation Loss Decreased(11.253892--->11.240959) \t Saving The Model\n",
            "Epoch 102 \t\t Train Accuracy: 0.671875 \t\t Training Loss: 0.636770449578762 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3208863615989685\n",
            "Validation Loss Decreased(11.240959--->11.231023) \t Saving The Model\n",
            "Epoch 103 \t\t Train Accuracy: 0.65625 \t\t Training Loss: 0.6496029496192932 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3209906816482544\n",
            "Epoch 104 \t\t Train Accuracy: 0.6796875 \t\t Training Loss: 0.6345595593253771 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3208440184593201\n",
            "Validation Loss Decreased(11.231023--->11.229541) \t Saving The Model\n",
            "Epoch 105 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6419795329372088 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3204523801803589\n",
            "Validation Loss Decreased(11.229541--->11.215833) \t Saving The Model\n",
            "Epoch 106 \t\t Train Accuracy: 0.64453125 \t\t Training Loss: 0.6457057098547617 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.320014750957489\n",
            "Validation Loss Decreased(11.215833--->11.200516) \t Saving The Model\n",
            "Epoch 107 \t\t Train Accuracy: 0.6875 \t\t Training Loss: 0.6257121314605077 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3195756196975708\n",
            "Validation Loss Decreased(11.200516--->11.185147) \t Saving The Model\n",
            "Epoch 108 \t\t Train Accuracy: 0.640625 \t\t Training Loss: 0.6462964912255605 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.31902916431427003\n",
            "Validation Loss Decreased(11.185147--->11.166021) \t Saving The Model\n",
            "Epoch 109 \t\t Train Accuracy: 0.64453125 \t\t Training Loss: 0.6473549082875252 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.31872164011001586\n",
            "Validation Loss Decreased(11.166021--->11.155257) \t Saving The Model\n",
            "Epoch 110 \t\t Train Accuracy: 0.640625 \t\t Training Loss: 0.644845133026441 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3184220552444458\n",
            "Validation Loss Decreased(11.155257--->11.144772) \t Saving The Model\n",
            "Epoch 111 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6460350578029951 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.31827099323272706\n",
            "Validation Loss Decreased(11.144772--->11.139485) \t Saving The Model\n",
            "Epoch 112 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6512078444163004 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.3325328350067139\n",
            "Epoch 113 \t\t Train Accuracy: 0.640625 \t\t Training Loss: 0.6490868702530861 \t\t Valid Accuracy: 0.5052083730697632 \t\t Validation Loss: 0.32820589542388917\n",
            "Epoch 114 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6370913063486418 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.318218994140625\n",
            "Validation Loss Decreased(11.139485--->11.137665) \t Saving The Model\n",
            "Epoch 115 \t\t Train Accuracy: 0.64453125 \t\t Training Loss: 0.6469275032480558 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.31811320781707764\n",
            "Validation Loss Decreased(11.137665--->11.133962) \t Saving The Model\n",
            "Epoch 116 \t\t Train Accuracy: 0.640625 \t\t Training Loss: 0.6512833336989085 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.31809157133102417\n",
            "Validation Loss Decreased(11.133962--->11.133205) \t Saving The Model\n",
            "Epoch 117 \t\t Train Accuracy: 0.6328125 \t\t Training Loss: 0.6569459140300751 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3182888388633728\n",
            "Epoch 118 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6478845303257307 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.318463397026062\n",
            "Epoch 119 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.6513120383024216 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.31873884201049807\n",
            "Epoch 120 \t\t Train Accuracy: 0.67578125 \t\t Training Loss: 0.6283829261859258 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.3186420679092407\n",
            "Epoch 121 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6401630863547325 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.31841143369674685\n",
            "Epoch 122 \t\t Train Accuracy: 0.625 \t\t Training Loss: 0.6554655209183693 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3182003617286682\n",
            "Epoch 123 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6350228389104208 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3181493282318115\n",
            "Epoch 124 \t\t Train Accuracy: 0.6328125 \t\t Training Loss: 0.651868425309658 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.318472158908844\n",
            "Epoch 125 \t\t Train Accuracy: 0.62109375 \t\t Training Loss: 0.6513636211554209 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.32695090770721436\n",
            "Epoch 126 \t\t Train Accuracy: 0.66015625 \t\t Training Loss: 0.6384241208434105 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.3360699534416199\n",
            "Epoch 127 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6324129849672318 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.3366680145263672\n",
            "Epoch 128 \t\t Train Accuracy: 0.66796875 \t\t Training Loss: 0.6294549976785978 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.33501688241958616\n",
            "Epoch 129 \t\t Train Accuracy: 0.65625 \t\t Training Loss: 0.6349055121342341 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.3348576664924622\n",
            "Epoch 130 \t\t Train Accuracy: 0.66015625 \t\t Training Loss: 0.6368581503629684 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.3362352132797241\n",
            "Epoch 131 \t\t Train Accuracy: 0.65625 \t\t Training Loss: 0.6347153509656588 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.33364770412445066\n",
            "Epoch 132 \t\t Train Accuracy: 0.6875 \t\t Training Loss: 0.6226505115628242 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.33557442426681516\n",
            "Epoch 133 \t\t Train Accuracy: 0.66796875 \t\t Training Loss: 0.629515161116918 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3254396080970764\n",
            "Epoch 134 \t\t Train Accuracy: 0.671875 \t\t Training Loss: 0.6224783062934875 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.3434530019760132\n",
            "Epoch 135 \t\t Train Accuracy: 0.66015625 \t\t Training Loss: 0.6331759045521418 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.34683244228363036\n",
            "Epoch 136 \t\t Train Accuracy: 0.671875 \t\t Training Loss: 0.6249942208329836 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.3472719669342041\n",
            "Epoch 137 \t\t Train Accuracy: 0.65234375 \t\t Training Loss: 0.6308664207657179 \t\t Valid Accuracy: 0.5104166865348816 \t\t Validation Loss: 0.32757493257522585\n",
            "Epoch 138 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6307261933883032 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.332256817817688\n",
            "Epoch 139 \t\t Train Accuracy: 0.640625 \t\t Training Loss: 0.643479585647583 \t\t Valid Accuracy: 0.51171875 \t\t Validation Loss: 0.3255859136581421\n",
            "Epoch 140 \t\t Train Accuracy: 0.671875 \t\t Training Loss: 0.6300435935457548 \t\t Valid Accuracy: 0.5104166865348816 \t\t Validation Loss: 0.32454060316085814\n",
            "Epoch 141 \t\t Train Accuracy: 0.703125 \t\t Training Loss: 0.6111807649334272 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.3177492141723633\n",
            "Validation Loss Decreased(11.133205--->11.121222) \t Saving The Model\n",
            "Epoch 142 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6363340318202972 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.3423231840133667\n",
            "Epoch 143 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6222372204065323 \t\t Valid Accuracy: 0.5052083730697632 \t\t Validation Loss: 0.34193480014801025\n",
            "Epoch 144 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6234967360893885 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34175026416778564\n",
            "Epoch 145 \t\t Train Accuracy: 0.6875 \t\t Training Loss: 0.6172910183668137 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.34105528593063356\n",
            "Epoch 146 \t\t Train Accuracy: 0.671875 \t\t Training Loss: 0.6288232381145159 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.34069883823394775\n",
            "Epoch 147 \t\t Train Accuracy: 0.671875 \t\t Training Loss: 0.6294126907984415 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.34109011888504026\n",
            "Epoch 148 \t\t Train Accuracy: 0.65234375 \t\t Training Loss: 0.6331462413072586 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.34137668609619143\n",
            "Epoch 149 \t\t Train Accuracy: 0.6640625 \t\t Training Loss: 0.6294252971808115 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.3403995394706726\n",
            "Epoch 150 \t\t Train Accuracy: 0.6796875 \t\t Training Loss: 0.6192190026243528 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.3399933099746704\n",
            "Epoch 151 \t\t Train Accuracy: 0.66015625 \t\t Training Loss: 0.6287077243129412 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.33937822580337523\n",
            "Epoch 152 \t\t Train Accuracy: 0.67578125 \t\t Training Loss: 0.6223398596048355 \t\t Valid Accuracy: 0.5091146230697632 \t\t Validation Loss: 0.33909029960632325\n",
            "Epoch 153 \t\t Train Accuracy: 0.65234375 \t\t Training Loss: 0.6309663007656733 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.33874193429946897\n",
            "Epoch 154 \t\t Train Accuracy: 0.66796875 \t\t Training Loss: 0.6273278072476387 \t\t Valid Accuracy: 0.5078125 \t\t Validation Loss: 0.33838934898376466\n",
            "Epoch 155 \t\t Train Accuracy: 0.66015625 \t\t Training Loss: 0.6315283005436262 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.33765363693237305\n",
            "Epoch 156 \t\t Train Accuracy: 0.640625 \t\t Training Loss: 0.6442184497912725 \t\t Valid Accuracy: 0.5052083730697632 \t\t Validation Loss: 0.33734056949615476\n",
            "Epoch 157 \t\t Train Accuracy: 0.63671875 \t\t Training Loss: 0.6394623244802157 \t\t Valid Accuracy: 0.5065104365348816 \t\t Validation Loss: 0.3366778135299683\n",
            "Epoch 158 \t\t Train Accuracy: 0.6484375 \t\t Training Loss: 0.6308651119470596 \t\t Valid Accuracy: 0.5052083730697632 \t\t Validation Loss: 0.33701430559158324\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-863-8acc6e63fef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-836-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-836-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-836-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-808-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-808-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-808-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-808-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-782-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-782-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-782-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-732-fe4069d229c2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-834-b0d267e9d4c0>\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-834-b0d267e9d4c0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-834-b0d267e9d4c0>\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for e in range(500):\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    model.train()     \n",
        "    for data, labels in train_dl:\n",
        "        if torch.cuda.is_available():\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        data = data.float()\n",
        "        target = model(data)\n",
        "        loss = loss_function(target,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_total += labels.shape[0]\n",
        "        train_correct += torch.sum(labels == target.argmax(dim=-1))\n",
        "    \n",
        "    train_accuracy = train_correct / train_total\n",
        "    valid_loss = 0.0\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    model.eval() \n",
        "    with torch.no_grad():   \n",
        "      for data, labels in valid_dl:\n",
        "          if torch.cuda.is_available():\n",
        "              data, labels = data.cuda(), labels.cuda()\n",
        "          data = data.float()\n",
        "          target = model(data)\n",
        "          loss = loss_function(target,labels)\n",
        "          valid_loss = loss.item() * data.size(0)\n",
        "          valid_loss += loss.item()\n",
        "          valid_total += labels.shape[0]\n",
        "          valid_correct += torch.sum(labels == target.argmax(dim=-1))\n",
        "      \n",
        "    valid_accuracy = valid_correct / valid_total\n",
        "\n",
        "    print(f'Epoch {e+1} \\t\\t Train Accuracy: {train_accuracy.item()} \\t\\t Training Loss: {train_loss / len(train_dl)} \\t\\t Valid Accuracy: {valid_accuracy.item()} \\t\\t Validation Loss: {valid_loss / len(valid_dl)}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
        "        min_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_model.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "EEG-Emotions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJqqPODdMPJo3DhMRYBY5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}